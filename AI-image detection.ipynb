{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b662f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  1950  y:  1950\n",
      "Epoch 1/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.6573 - loss: 0.6947 - precision: 0.6573 - val_accuracy: 0.5670 - val_loss: 1.2411 - val_precision: 0.5670\n",
      "Epoch 2/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.7681 - loss: 0.4972 - precision: 0.7681 - val_accuracy: 0.5670 - val_loss: 31.1374 - val_precision: 0.5670\n",
      "Epoch 3/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.8379 - loss: 0.4199 - precision: 0.8379 - val_accuracy: 0.4330 - val_loss: 1.2228 - val_precision: 0.4330\n",
      "Epoch 4/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.8661 - loss: 0.3391 - precision: 0.8661 - val_accuracy: 0.4330 - val_loss: 1.1324 - val_precision: 0.4330\n",
      "Epoch 5/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9031 - loss: 0.3162 - precision: 0.9031 - val_accuracy: 0.4330 - val_loss: 1.0283 - val_precision: 0.4330\n",
      "Epoch 6/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.8736 - loss: 0.3291 - precision: 0.8736 - val_accuracy: 0.4330 - val_loss: 2.4734 - val_precision: 0.4330\n",
      "Epoch 7/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9013 - loss: 0.2378 - precision: 0.9013 - val_accuracy: 0.4330 - val_loss: 5.4275 - val_precision: 0.4330\n",
      "Epoch 8/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9211 - loss: 0.1990 - precision: 0.9211 - val_accuracy: 0.4330 - val_loss: 1.4902 - val_precision: 0.4330\n",
      "Epoch 9/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9367 - loss: 0.1801 - precision: 0.9367 - val_accuracy: 0.4330 - val_loss: 6.7862 - val_precision: 0.4330\n",
      "Epoch 10/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9582 - loss: 0.1256 - precision: 0.9582 - val_accuracy: 0.4815 - val_loss: 1.4686 - val_precision: 0.4815\n",
      "Epoch 11/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9676 - loss: 0.1139 - precision: 0.9676 - val_accuracy: 0.4330 - val_loss: 3.7502 - val_precision: 0.4330\n",
      "Epoch 12/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9533 - loss: 0.1539 - precision: 0.9533 - val_accuracy: 0.4473 - val_loss: 4.5766 - val_precision: 0.4473\n",
      "Epoch 13/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9586 - loss: 0.1333 - precision: 0.9586 - val_accuracy: 0.5299 - val_loss: 1.7300 - val_precision: 0.5299\n",
      "Epoch 14/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9506 - loss: 0.1225 - precision: 0.9506 - val_accuracy: 0.5584 - val_loss: 2.5151 - val_precision: 0.5584\n",
      "Epoch 15/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9622 - loss: 0.1169 - precision: 0.9622 - val_accuracy: 0.6752 - val_loss: 4.3558 - val_precision: 0.6752\n",
      "Epoch 16/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9626 - loss: 0.1096 - precision: 0.9626 - val_accuracy: 0.5897 - val_loss: 2.8614 - val_precision: 0.5897\n",
      "Epoch 17/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9654 - loss: 0.0856 - precision: 0.9654 - val_accuracy: 0.5755 - val_loss: 2.4054 - val_precision: 0.5755\n",
      "Epoch 18/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.9594 - loss: 0.1146 - precision: 0.9594 - val_accuracy: 0.7721 - val_loss: 1.1034 - val_precision: 0.7721\n",
      "Epoch 19/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.9822 - loss: 0.0882 - precision: 0.9822 - val_accuracy: 0.7066 - val_loss: 2.5767 - val_precision: 0.7066\n",
      "Epoch 20/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.9476 - loss: 0.1737 - precision: 0.9476 - val_accuracy: 0.7778 - val_loss: 0.8885 - val_precision: 0.7778\n",
      "Epoch 21/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.9793 - loss: 0.0775 - precision: 0.9793 - val_accuracy: 0.8034 - val_loss: 0.9902 - val_precision: 0.8034\n",
      "Epoch 22/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.9886 - loss: 0.0499 - precision: 0.9886 - val_accuracy: 0.8575 - val_loss: 1.2131 - val_precision: 0.8575\n",
      "Epoch 23/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.9665 - loss: 0.0911 - precision: 0.9665 - val_accuracy: 0.8205 - val_loss: 1.0359 - val_precision: 0.8205\n",
      "Epoch 24/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.9771 - loss: 0.0747 - precision: 0.9771 - val_accuracy: 0.8034 - val_loss: 0.9829 - val_precision: 0.8034\n",
      "Epoch 25/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - accuracy: 0.9674 - loss: 0.1169 - precision: 0.9674 - val_accuracy: 0.8433 - val_loss: 0.8929 - val_precision: 0.8433\n",
      "Epoch 26/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.9775 - loss: 0.0745 - precision: 0.9775 - val_accuracy: 0.8177 - val_loss: 0.8528 - val_precision: 0.8177\n",
      "Epoch 27/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0298 - precision: 0.9918 - val_accuracy: 0.8547 - val_loss: 1.2711 - val_precision: 0.8547\n",
      "Epoch 28/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.9928 - loss: 0.0238 - precision: 0.9928 - val_accuracy: 0.8889 - val_loss: 1.3352 - val_precision: 0.8889\n",
      "Epoch 29/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.9836 - loss: 0.0435 - precision: 0.9836 - val_accuracy: 0.6724 - val_loss: 2.8994 - val_precision: 0.6724\n",
      "Epoch 30/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.9863 - loss: 0.0488 - precision: 0.9863 - val_accuracy: 0.8860 - val_loss: 0.8042 - val_precision: 0.8860\n",
      "Epoch 31/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - accuracy: 0.9881 - loss: 0.0338 - precision: 0.9881 - val_accuracy: 0.8234 - val_loss: 0.9554 - val_precision: 0.8234\n",
      "Epoch 32/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9932 - loss: 0.0324 - precision: 0.9932 - val_accuracy: 0.7806 - val_loss: 0.9873 - val_precision: 0.7806\n",
      "Epoch 33/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0811 - precision: 0.9752 - val_accuracy: 0.8718 - val_loss: 1.1769 - val_precision: 0.8718\n",
      "Epoch 34/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.9913 - loss: 0.0254 - precision: 0.9913 - val_accuracy: 0.8775 - val_loss: 0.9088 - val_precision: 0.8775\n",
      "Epoch 35/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.9800 - loss: 0.0556 - precision: 0.9800 - val_accuracy: 0.8234 - val_loss: 0.7242 - val_precision: 0.8234\n",
      "Epoch 36/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9865 - loss: 0.0400 - precision: 0.9865 - val_accuracy: 0.8775 - val_loss: 1.6684 - val_precision: 0.8775\n",
      "Epoch 37/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0323 - precision: 0.9924 - val_accuracy: 0.8661 - val_loss: 1.3642 - val_precision: 0.8661\n",
      "Epoch 38/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0206 - precision: 0.9953 - val_accuracy: 0.8917 - val_loss: 0.8719 - val_precision: 0.8917\n",
      "Epoch 39/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9942 - loss: 0.0192 - precision: 0.9942 - val_accuracy: 0.8519 - val_loss: 0.5312 - val_precision: 0.8519\n",
      "Epoch 40/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9694 - loss: 0.0885 - precision: 0.9694 - val_accuracy: 0.7607 - val_loss: 1.6891 - val_precision: 0.7607\n",
      "Epoch 41/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 1s/step - accuracy: 0.9801 - loss: 0.0730 - precision: 0.9801 - val_accuracy: 0.7749 - val_loss: 2.6832 - val_precision: 0.7749\n",
      "Epoch 42/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9918 - loss: 0.0290 - precision: 0.9918 - val_accuracy: 0.7721 - val_loss: 5.3690 - val_precision: 0.7721\n",
      "Epoch 43/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9777 - loss: 0.0595 - precision: 0.9777 - val_accuracy: 0.7550 - val_loss: 1.9535 - val_precision: 0.7550\n",
      "Epoch 44/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9784 - loss: 0.0748 - precision: 0.9784 - val_accuracy: 0.7892 - val_loss: 4.1942 - val_precision: 0.7892\n",
      "Epoch 45/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9910 - loss: 0.0571 - precision: 0.9910 - val_accuracy: 0.5983 - val_loss: 2.6066 - val_precision: 0.5983\n",
      "Epoch 46/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9554 - loss: 0.1223 - precision: 0.9554 - val_accuracy: 0.8433 - val_loss: 0.9059 - val_precision: 0.8433\n",
      "Epoch 47/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0254 - precision: 0.9954 - val_accuracy: 0.8575 - val_loss: 1.5565 - val_precision: 0.8575\n",
      "Epoch 48/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9899 - loss: 0.0244 - precision: 0.9899 - val_accuracy: 0.7977 - val_loss: 1.6213 - val_precision: 0.7977\n",
      "Epoch 49/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9842 - loss: 0.0549 - precision: 0.9842 - val_accuracy: 0.8604 - val_loss: 1.3599 - val_precision: 0.8604\n",
      "Epoch 50/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9948 - loss: 0.0138 - precision: 0.9948 - val_accuracy: 0.8775 - val_loss: 1.0399 - val_precision: 0.8775\n",
      "Epoch 51/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9910 - loss: 0.0250 - precision: 0.9910 - val_accuracy: 0.8832 - val_loss: 1.1074 - val_precision: 0.8832\n",
      "Epoch 52/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9956 - loss: 0.0124 - precision: 0.9956 - val_accuracy: 0.9003 - val_loss: 0.9324 - val_precision: 0.9003\n",
      "Epoch 53/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9849 - loss: 0.0431 - precision: 0.9849 - val_accuracy: 0.8775 - val_loss: 0.8335 - val_precision: 0.8775\n",
      "Epoch 54/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9883 - loss: 0.0316 - precision: 0.9883 - val_accuracy: 0.8832 - val_loss: 0.9347 - val_precision: 0.8832\n",
      "Epoch 55/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9967 - loss: 0.0152 - precision: 0.9967 - val_accuracy: 0.8860 - val_loss: 1.1198 - val_precision: 0.8860\n",
      "Epoch 56/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0090 - precision: 0.9923 - val_accuracy: 0.8889 - val_loss: 1.2757 - val_precision: 0.8889\n",
      "Epoch 57/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9901 - loss: 0.0387 - precision: 0.9901 - val_accuracy: 0.8519 - val_loss: 0.9957 - val_precision: 0.8519\n",
      "Epoch 58/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0243 - precision: 0.9947 - val_accuracy: 0.9060 - val_loss: 0.5711 - val_precision: 0.9060\n",
      "Epoch 59/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9929 - loss: 0.0303 - precision: 0.9929 - val_accuracy: 0.9031 - val_loss: 1.0328 - val_precision: 0.9031\n",
      "Epoch 60/60\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 1s/step - accuracy: 0.9960 - loss: 0.0086 - precision: 0.9960 - val_accuracy: 0.8775 - val_loss: 1.5873 - val_precision: 0.8775\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 473ms/step\n",
      "Validation Precision: 0.82\n",
      "Validation Accuracy: 0.88\n",
      "Validation Recall: 0.91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step\n",
      "Test Precision: 0.90\n",
      "Test Accuracy: 0.91\n",
      "Test Recall: 0.94\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def extract_feature(image):\n",
    "    image_data = cv2.imread(image)\n",
    "    img_gray = cv2.cvtColor(image_data, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_keypoints = sift.detect(image_data, None)\n",
    "    sift_g_keypoints = sift.detect(img_gray, None)\n",
    "    img_keys = cv2.drawKeypoints(image_data, sift_keypoints, None)\n",
    "    img_gray_keys = cv2.drawKeypoints(img_gray, sift_g_keypoints, None)\n",
    "    img_keys = cv2.resize(img_keys, (224, 224))\n",
    "    img_gray_keys = cv2.resize(img_gray_keys, (224, 224))\n",
    "    img_keys = img_keys / 255.0\n",
    "    img_gray_keys = img_gray_keys / 255.0\n",
    "    tensor_img = tf.convert_to_tensor(img_keys)\n",
    "    tensor_img_gray = tf.convert_to_tensor(img_gray_keys)\n",
    "    return tensor_img, tensor_img_gray\n",
    "\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    print('Loading dataset...')\n",
    "    X = []\n",
    "    y = []\n",
    "    print('Extracting features...')\n",
    "    for label in os.listdir(data_dir):\n",
    "        label_dir = os.path.join(data_dir, label)\n",
    "        for image_file in os.listdir(label_dir):\n",
    "            image_path = os.path.join(label_dir, image_file)\n",
    "            image_tensor, gray_image_tensor = extract_feature(image_path)\n",
    "            X.append(image_tensor)\n",
    "            X.append(gray_image_tensor)\n",
    "            y.append(label)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    print(\"Training model...\")\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    adam_optimizer = Adam(learning_rate=0.003)\n",
    "    \n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy', 'precision'])\n",
    "    # model.fit(X_train, to_categorical(y_train), validation_data=(X_val, to_categorical(y_val)), epochs=60, batch_size=32)\n",
    "    \n",
    "    history = model.fit(X_train, to_categorical(y_train), validation_data=(X_val, to_categorical(y_val)), epochs=60, batch_size=32)\n",
    "        \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def validate_model(model, X_val, y_val):\n",
    "    print(\"Validating model...\")\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    precision = precision_score(y_val, y_pred_classes, zero_division=0)\n",
    "    accuracy = accuracy_score(y_val, y_pred_classes)\n",
    "    recall = recall_score(y_val, y_pred_classes)\n",
    "    return precision, accuracy, recall\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    print(\"Testing model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    precision = precision_score(y_test, y_pred_classes, zero_division=0)\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "    recall = recall_score(y_test, y_pred_classes)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred[:, 1])  # Assuming binary classification and considering probability of positive class\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show()\n",
    "    return precision, accuracy, recall\n",
    "\n",
    "\n",
    "data_dir = r'C:\\Users\\adepojuh\\Documents\\project\\ai_and _real'\n",
    "X, y = load_dataset(data_dir)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "print(\"X: \", len(X), ' y: ', len(y))\n",
    "# print(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model = train_model(X_train, y_train, X_val, y_val)\n",
    "val_precision, val_accuracy, val_recall = validate_model(model, X_val, y_val)\n",
    "print(f\"Validation Precision: {val_precision:.2f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
    "print(f\"Validation Recall: {val_recall:.2f}\")\n",
    "\n",
    "test_precision, test_accuracy, test_recall = test_model(model, X_test, y_test)\n",
    "print(f\"Test Precision: {test_precision:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Test Recall: {test_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79b9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
